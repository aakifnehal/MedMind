# ğŸ©º MedMind - AI-Powered Medical Document Assistant

![MedMind Banner](./public/UI.png)

[![Python](https://img.shields.io/badge/Python-3.13+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-Latest-red.svg)](https://streamlit.io)
[![LangChain](https://img.shields.io/badge/LangChain-Latest-yellow.svg)](https://langchain.com)
[![License](https://img.shields.io/badge/License-MIT-orange.svg)](LICENSE)

## ğŸ¯ Overview

**MedMind** is an AI-powered medical document assistant designed specifically to help **medical students during their internship period**. The application bridges the gap between traditional paper-based patient medical histories and modern AI technology, enabling students to better understand diseases by comparing patient data with their study materials and medical literature.

### ğŸ“ Target Audience
- **Medical Students** in their internship/clinical rotation phase
- **Medical Residents** seeking quick reference and understanding
- **Healthcare Educators** looking for teaching aids

## â— Problem Statement

The medical history of patients is typically available only on paper, making it challenging to:
- **Compare patient data** with medical textbooks and literature
- **Quickly understand** complex medical conditions and terminology
- **Correlate symptoms** with potential diagnoses
- **Access relevant study material** in real-time during patient care

**MedMind solves this by:**
- Digitizing and analyzing medical documents using AI
- Providing instant, contextual answers about patient conditions
- Enabling comparison with medical knowledge bases
- Offering educational insights for better learning

## âœ¨ Features

### ğŸ”§ Core Functionality
- **ğŸ“„ Multi-PDF Upload**: Process multiple medical documents simultaneously
- **ğŸ¤– AI-Powered Q&A**: Ask natural language questions about uploaded documents
- **ğŸ” Intelligent Search**: Vector-based semantic search through document content
- **ğŸ“š Source Citation**: Provides references to specific document sections
- **ğŸ’¬ Interactive Chat**: Real-time conversation interface with medical documents
- **ğŸ“¥ Chat History Export**: Download conversation history for future reference

### ğŸ¯ Medical-Specific Features
- **ğŸ©º Medical Terminology Understanding**: Explains complex medical terms
- **ğŸ“Š Test Result Analysis**: Helps interpret lab reports and diagnostic results
- **ğŸ’Š Medication Information**: Provides insights on prescribed medications
- **ğŸ”¬ Treatment Recommendations**: Summarizes treatment plans and procedures

### ğŸ›¡ï¸ Safety & Privacy
- **ğŸš« No Medical Advice**: Clearly disclaims diagnostic capabilities
- **ğŸ”’ Local Processing**: Documents processed securely
- **âš ï¸ Educational Focus**: Designed for learning, not clinical decision-making

## ğŸ—ï¸ Technical Architecture

```mermaid
graph TB
    A[Streamlit Frontend] --> B[FastAPI Backend]
    B --> C[LangChain Processing]
    C --> D[Google Generative AI Embeddings]
    C --> E[Groq LLM - Llama3 70B]
    D --> F[Pinecone Vector Database]
    G[PDF Documents] --> H[PyPDF Loader]
    H --> I[Text Splitter]
    I --> D
    F --> J[Retrieval QA Chain]
    J --> E
    E --> K[AI Response]
```

### ğŸ”„ Workflow
1. **Document Upload**: PDFs uploaded via Streamlit interface
2. **Text Extraction**: PyPDF extracts text content from documents
3. **Text Chunking**: Documents split into manageable chunks (500 chars, 100 overlap)
4. **Embedding Generation**: Google GenAI creates vector embeddings
5. **Vector Storage**: Embeddings stored in Pinecone database
6. **Query Processing**: User questions embedded and matched against vectors
7. **Context Retrieval**: Relevant document chunks retrieved
8. **AI Response**: Groq's Llama3-70B generates contextual answers

## ğŸ› ï¸ Tech Stack

### **Frontend**
- **Streamlit** - Interactive web interface
- **Python Requests** - API communication

### **Backend**
- **FastAPI** - High-performance web framework
- **Uvicorn** - ASGI server
- **Python Multipart** - File upload handling

### **AI/ML Stack**
- **LangChain** - LLM application framework
- **LangChain Community** - Document loaders and utilities
- **Groq API** - Llama3-70B-8192 language model
- **Google Generative AI** - Text embeddings (embedding-001)
- **Pinecone** - Vector database for similarity search

### **Document Processing**
- **PyPDF** - PDF text extraction
- **RecursiveCharacterTextSplitter** - Intelligent text chunking

### **Infrastructure**
- **Pydantic** - Data validation
- **Python-dotenv** - Environment variable management
- **Loguru** - Advanced logging
- **TQDM** - Progress bars

## ğŸš€ Installation

### Prerequisites
- Python 3.13+
- Groq API Key
- Google AI API Key
- Pinecone API Key

### 1. Clone Repository
```bash
git clone https://github.com/aakifnehal/MedMind.git
cd MedMind
```

### 2. Set Up Backend
```bash
cd server
pip install -r requirements.txt
```

### 3. Set Up Frontend
```bash
cd ../client
pip install -r requirements.txt
```

### 4. Environment Configuration
Create `.env` file in the `server` directory:
```env
GROQ_API_KEY=your_groq_api_key_here
GOOGLE_API_KEY=your_google_ai_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=medmind-index
```

### 5. Start Backend Server
```bash
cd server
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 6. Start Frontend
```bash
cd client
streamlit run app.py
```

## ğŸ“– Usage

### 1. **Upload Medical Documents**
- Navigate to the sidebar
- Upload one or multiple PDF documents
- Wait for processing completion

### 2. **Ask Questions**
- Type your question in the chat interface
- Example questions:
  - "What are the key findings in the lab results?"
  - "Explain the diagnosis mentioned in the report"
  - "What medications were prescribed and why?"
  - "Summarize the treatment recommendations"

### 3. **Review Responses**
- Get AI-powered answers with source citations
- View relevant document sections
- Download chat history for future reference

## ğŸ“¡ API Documentation

### Upload Endpoint
```http
POST /upload_pdfs/
Content-Type: multipart/form-data

files: List[UploadFile]
```

### Query Endpoint
```http
POST /ask/
Content-Type: application/x-www-form-urlencoded

question: string
```

### Response Format
```json
{
  "response": "AI-generated answer",
  "sources": ["document1.pdf", "document2.pdf"]
}
```

## ğŸ“ Project Structure

```
MedMind/
â”œâ”€â”€ ğŸ“± client/                    # Streamlit Frontend
â”‚   â”œâ”€â”€ app.py                   # Main application
â”‚   â”œâ”€â”€ config.py                # API configuration
â”‚   â”œâ”€â”€ requirements.txt         # Frontend dependencies
â”‚   â”œâ”€â”€ ğŸ§© components/
â”‚   â”‚   â”œâ”€â”€ chatUI.py           # Chat interface
â”‚   â”‚   â”œâ”€â”€ upload.py           # File upload component
â”‚   â”‚   â””â”€â”€ history_download.py # Chat history export
â”‚   â””â”€â”€ ğŸ”§ utils/
â”‚       â””â”€â”€ api.py              # API client functions
â”œâ”€â”€ ğŸ–¥ï¸ server/                   # FastAPI Backend
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ logger.py               # Logging configuration
â”‚   â”œâ”€â”€ requirements.txt        # Backend dependencies
â”‚   â”œâ”€â”€ ğŸ› ï¸ modules/
â”‚   â”‚   â”œâ”€â”€ llm.py             # LLM chain configuration
â”‚   â”‚   â”œâ”€â”€ load_vectorstore.py # Vector database operations
â”‚   â”‚   â”œâ”€â”€ query_handler.py    # Query processing
â”‚   â”‚   â””â”€â”€ pdf_handlers.py     # PDF processing utilities
â”‚   â”œâ”€â”€ ğŸ›£ï¸ routes/
â”‚   â”‚   â”œâ”€â”€ upload_pdfs.py      # Upload endpoint
â”‚   â”‚   â””â”€â”€ ask_question.py     # Query endpoint
â”‚   â”œâ”€â”€ ğŸ”§ middleware/
â”‚   â”‚   â””â”€â”€ exception_handlers.py # Error handling
â”‚   â””â”€â”€ ğŸ“ uploaded_docs/       # Document storage
â”œâ”€â”€ ğŸ–¼ï¸ public/
â”‚   â””â”€â”€ UI.png                  # Application banner
â”œâ”€â”€ pyproject.toml              # Project configuration
â””â”€â”€ README.md                   # This file
```

## ğŸ” Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `GROQ_API_KEY` | Groq API key for Llama3 model | Yes |
| `GOOGLE_API_KEY` | Google AI API key for embeddings | Yes |
| `PINECONE_API_KEY` | Pinecone API key for vector database | Yes |
| `PINECONE_INDEX_NAME` | Pinecone index name (default: medmind-index) | Yes |

## âš ï¸ Important Disclaimer

**MedMind is designed for educational purposes only and should not be used as a substitute for professional medical advice, diagnosis, or treatment.**

- ğŸš« **Not for Clinical Decisions**: Do not use for making clinical decisions
- ğŸ‘¨â€âš•ï¸ **Consult Professionals**: Always consult qualified healthcare professionals
- ğŸ“š **Educational Tool**: Intended to supplement medical education, not replace it
- ğŸ” **Verify Information**: Always verify AI responses with authoritative medical sources
- ğŸ“‹ **No Liability**: Developers assume no liability for medical decisions based on this tool

## ğŸ™ Acknowledgments

- **LangChain** team for the excellent LLM framework
- **Groq** for providing fast LLM inference
- **Google AI** for embedding models
- **Pinecone** for vector database services
- **Streamlit** team for the intuitive frontend framework
- **Medical Education Community** for inspiration and feedback

## ğŸ“ Support

For questions, issues, or contributions:
- ğŸ› [Open an Issue](https://github.com/aakifnehal/MedMind/issues)
- ğŸ’¬ [Discussions](https://github.com/aakifnehal/MedMind/discussions)

---

<div align="center">
  <strong>Built with â¤ï¸ for Medical Education</strong><br>
  <em>Empowering the next generation of healthcare professionals</em>
</div>
